file,online score,val score (weighted avg f1), f1 fraud,changelog
2025.03.03_14:44:20_models.rf_test.csv,0.4389078498293515,0.85,0.47,Simple RF only trained on training set
2025.03.03_14:58:23_models.rf.txt,0.44907723855092274,,,Simple RF but trained on train+val+kaggle -> seems to make sense to train on all data
2025.03.04_10.22.19_models.rf_test.csv,0.20561506004543978,0.81,0.67,Simple RF but on features ver01 and retrained on all data -> for some reason that had predicted only fraudsters -> should i be able to calc percentage of fraud here?
2025.03.04_10.22.19_models.rf_test.csv modified,0.0,-,-,Contains only non-fraudsters for percentage calc reasons
2025.03.21_15.38.02_simple_cnn_test.txt,0.9318555008210181,0.96,0.93,Simple CNN trained on ver05 train set
2025.03.21_16.22.16_simple_cnn_test.csv,0.9338809034907597,-,0.935(Tensorboard),Simple CNN trained on a mix of train and val. Performance is not much better then per set. The classification report is skewed tho -> thats why i included the tensorboard log
2025.03.24_13.04.48_attn_cnn2_test.csv,0.9330677290836653,0.96,0.94,CNN with multiple attention layers. The curious thing is that this model as the first in quite some time hase a balanced precision and recall for fraudsters. The model is trained on ver05 train set
2025.03.26_12.24.12_attn_cnn_test.csv,0.9517241379310344,0.97,0.95,Attn CNN trained on ver08 (tensorboard attn_cnn/version_26)
2025.03.31_12.04.44_rec_cnn4_test.csv,0.9960629921259844,1.0,1.0,Rec CNN utilizing simple_cnn (ver51) trained on ver12 with the gnf features only for transaction